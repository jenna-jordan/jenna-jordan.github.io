- title: About me
  type: map
  contents:
    - name: Full Name
      value: Jennifer (Jenna) Jordan
    - name: Job Title 
      value: Data Engineer
    - name: Citizenship
      value: USA

- title: Skills
  type: list
  contents:
    - "Languages: python, SQL, git, bash, YAML/YAQL, regex, Xpath"
    - "Featured Libraries: dbt, pandas, plotly, streamlit, SQLAlchemy, Great Expectations"
    - "Databases: PostgreSQL (and PostGIS), SQLite, duckdb"
    - "Other Tools: GitHub, Civis Platform, Jira"
    - "data modeling & architecture/design - 3rd Normal Form, ER Diagrams, star schema, etc"
    - "creating and managing ETL/ELT pipelines; data orchestration"
    - "data wrangling, visualization, and exploratory data analysis"
    - "teaching workshops; writing documentation; presenting projects"

- title: Experience
  type: time_table
  contents:
    - title: Data Engineer
      institution: Analytics Team, Department of Innovation & Technology, City of Boston
      year: Jan 2022 - present
      description:
        - Manage the data warehouse and ETL pipelines for the City of Boston's Analytics Team.
        - Write custom component scripts in python to ingest and export data.
        - Transform data using SQL and write data unit tests using Great Expectations.
        - Ensure the analysts have high quality, reliable data for analytics end products (e.g. dashboards) and the public has up to date access to open data published on Analyze Boston.
        - Initiated, planned, and managed the execution of an ETL workflow redesign that centered on implementing dbt within a new set of schemas.
        - Led the implementation of dbt for the Analytics team's data warehouse and the adoption of the dbt-generated Data Catalog.
    
    - title: Data Engineer, Computational Methods Instructor (Contractor)
      institution: Network Contagion Research Institute (NCRI)
      year: Jan 2021 - Nov 2021
      description:
        - Built ingest pipelines (with Python) and designed relational databases for the data to add new social media communities (Telegram, 4-chan) to Pushshift in order to support NCRI's mission of identifying disinformation and extremism on social media.
        - title: Ran the Computational Methods group for interns at NCRI Labs (Summer and Fall 2021 semesters)
          contents:
            - Designed a semester-long curriculum for computational skills.
            - Taught weekly workshops on Bash, Git, Python, SQL, and regex (using the Software Carpentries lesson plans).
            - Supervised independent projects.

    - title: Marketing Data Analyst (Contractor)
      institution: Bright Wolf
      year: Sep 2020 - Apr 2021
      description:
        - Organized, managed, visualized, and analyzed marketing-related data; supported & audited email campaigns.
        - Built a data pipeline that integrated data from Salesforce, EverString (now ZoomInfo), and other sources into one cohesive relational database, and then used that database to power a dashboard that visualized the available data for potential corporate clients. Utilized the Streamlit, Plotly, and SQLAlchemy Python libraries.

    - title: Graduate Research Assistant
      institution: Cline Center for Advanced Social Research, University of Illinois at Urbana-Champaign
      year: Aug 2019 - May 2020
      description:
        - Supported the Cline Center with data releases by preparing/cleaning data, updating documentation, and coordinating with the data repository.
        - Promoted the Global News Index by preparing and helping to present tutorials.
        - Developed a user feedback process for Cline Center software applications and data releases.
        - Other support tasks as needed.

    - title: Data Science Intern
      institution: The Program on Governance and Local Development (GLD), University of Gothenburg
      year: May 2019 - Jul 2019
      description: 
        - Assisted the Data Scientist on data monitoring tasks for an ongoing survey (LGPI 2019) being conducted in Zambia and Kenya - for example, one data monitoring task was to make sure that enumerators completed the requisite number of surveys in each designated hectare, according to the sampling plan.
        - Wrote Python scripts to organize and wrangle data downloaded from SurveyToGo, edited surveys in SurveyToGo, worked with geospatial data using Python and QGIS, and helped to develop the Local Governance Performance Index based on data collected from the survey.
        - Worked extensively with large XML documents, and wrote custom scripts to extract data from KML files and reformat into WKT files.
        - Attended the 2019 Annual GLD Conference, which focused on the theme "Routes to Accountability."

    - title: Graduate Research Assistant
      institution: Cline Center for Advanced Social Research, University of Illinois at Urbana-Champaign
      year: Jan 2019 - May 2019
      description:
        - Created user-friendly documentation for the Cline Center’s Global News Index using Adobe InDesign.
        - Wrote an in-depth codebook on the GNI’s variables and corpora, a detailed user guide and a quick-start guide on Archer (the in-house software developed to query the GNI) and a guide on using Solr to query the GNI. 
        - Helped to test, document bugs, and suggest features for Archer (software application recently developed by the Cline Center), and assisted users in querying the GNI.

    - title: Research Assistant (graduate hourly position)
      institution: iSchool, University of Illinois at Urbana-Champaign
      year: Sep 2018 - Dec 2018
      description:
        - Investigated and compiled a corpus on Data Management Plans (DMPs) for Prof. Peter Darch.
        - Annotated datasets for use in human-in-the-loop machine learning analyses performed by Prof. Jana Diesner’s research group.

    - title: English Teacher
      institution: Corem Language Institue, South Korea
      year: Jun 2016 - Aug 2017
      description:
        - Taught English as a Foreign Language to Kindergarten and Elementary students in Yangsan, South Korea, at a private academy (hagwon). I taught an average of 8 40-minute classes each day.
        - My kindergarten students were 5-6 years old. In addition to teaching basic reading, writing, and conversational skills I taught fun math, science, and arts & crafts lessons. I also wrote bimonthly progress reports for each student, administered occasional tests, and helped to conduct monthly “phone interviews” with the students in the upper-level classes.
        - My elementary students were 7-12 years old. In addition to teaching language lessons, I was in charge of making and grading their tests and writing bimonthly progress reports for each student.

    - title: Intern
      institution: U.S. Mission to the UN at Washington, DC (USUNW), U.S. Department of State
      year: Jan 2014 - Apr 2014
      description:
        - Worked as part of a small team advising the U.S. Ambassador to the United Nations Samantha Power, serving as a bridge between the United Nations, the Executive Office, and the National Security Council.
        - Supported the Senior Policy Advisors, Speechwriter, and Executive Assistant with research, copywriting, and administrative tasks.
        - Wrote executive summaries and took notes on office, cross-bureau, and inter-departmental meetings for the USUNW team.

- title: Publications & Presentations
  type: time_table
  contents:
    - title: "From coast to coast: implementing dbt in the public sector"
      institution: Coalesce 2023 (by dbt Labs), San Diego
      year: presented Oct 2023
      description:
        - Presented about Boston's implementation of dbt in order to improve data services and data engineering practices, while my cospeakers presented about their projects for the State of California and Cal-ITP.
        - This session discusses the similarities and differences between the implementations of dbt, and how some of the constraints and challenges of working in government shape both the technical and social design of data services. The speakers reflect on successes, challenges, and lessons learned about adopting modern data tooling in state and local governments.
    
    - title: "Interactive Data Visualizations in Python"
      institution: The Carpentries, Lesson Incubator
      year: published Aug 2021
      description:
        - Developed a Carpentries workshop lesson designed to be an introduction to making interactive visualizations in python.
        - Learners create a new environment using conda, wrangle data into the proper format using pandas library, create visualizations using the Plotly Python library, and display these visualizations and create widgets using Streamlit.
   
    - title: "No buzz for bees: Media coverage of pollinator decline"
      institution: Proceedings of the National Academy of Sciences (PNAS)
      year: published Jan 2021
      description:
        - Co-author on Perspective paper submitted to PNAS in March 2020, published Jan 2021.
        - Wrote the ETL scripts to collect data from the Global News Index and transform the data for analysis & visualization, created an interactive visualization tool to aid in exploratory data analysis, and wrote the documentation for the data & code deposited in the Illinois Data Bank.
    
    - title: "Python can be tidy too: pandas recipes for normalizing data"
      institution: PyCon 2020 (virtual)
      year: published May 2020
      description:
        - Published poster online for PyCon 2020 (conference moved online-only due to COVID-19)
        - Demonstrates a collection of recipes from my Tidy Pandas Cookbook that draw on the “tidy data” and “3rd normal form” philosophies of data organization, using data from the Correlates of War and Uppsala Conflict Data Program.
     
    - title: "Put Relational Databases in Your Data Curation Toolbox"
      institution: Proceedings of the Association for Information Science and Technology (ASIS&T 82nd Annual Meeting; in Melbourne, Australia)
      year: presented Oct 2019
      description:
        - Presented my poster advocating the use of relational databases in the data curation process, especially for datasets that are published separately but can be used together due to a common identifier scheme and shared attributes. 
        - The Correlates of War datasets are used as an illustrative example to show how the normalization process results in a design with greater data reusability, while check constraints and foreign key constraints can improve data quality.

- title: Education
  type: time_table
  contents:
    - title: Master of Science, Library and Information Science
      institution: University of Illinois at Urbana-Champaign
      year: 2020
      description:
        - 3.97 GPA
    - title: Bachelor of Arts, Journalism, Political Science
      institution: University of North Carolina at Chapel Hill
      year: 2015
      description:
        - Graduated with Honors
        - 3.61 GPA

- title: Certificates
  type: time_table
  contents:

    - title: dbt Developer
      institution: dbt Labs
      year: 2023

    - title: Analytics Engineering with dbt
      institution: CoRise
      year: 2022

    - title: Software Carpentries Certified Instructor
      institution: The Carpentries
      year: 2020

    - title: CELTA, Teaching English as a Foreign Language
      institution: International House Budapest
      year: 2016